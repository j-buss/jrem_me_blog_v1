---
title: Transformations and Weighting to Correct Model Inadequacies
author: Jeremy Buss
date: '2021-10-20'
slug: []
categories:
  - Introduction to Linear Regression Analysis - Montgomery/Peck/Vining
  - Applied Stats
  - Regression Analysis
tags:
  - R
  - linear regression
draft: true
katex: yes
---
```{r echo=FALSE}
library(blogdown)
```

## Model Assumptions

Regression model fitting has several implicit assumptions, including:

* $\epsilon \overset{iid}{\sim} NID(0,\sigma^2)$: **mean 0**, **constant variance**, **normally distributed**, and **uncorrelated** 
* The form of the model (**linearity**) and the specification of the predictors are correct.
* Check model adequacy by residual plots and lack-of-fit tests
* Methods when some assumptions are violated:
  * Data Transformation
  * Generalized Least Squares (GLS)
  * Weighted Least Squares (WLS)

## Data Transformation

### Variance Stabilization

The constant variance assumption is often violated when the response $y$ follows a distribution which is related to the mean.  
* Problems can be identified by examining the residual plots
* Variance stabilizing transformations can be selected empirically
  * If $\sigma^2$ is not constant, the coefficients will have larger standard errors (no longer BLUE)

```{r echo=FALSE, results='asis', escape=FALSE}
x <- data.frame("Relationship" = c("$\\sigma^2 \\propto \\text{constant}$",
                                   "$\\sigma^2 \\propto E(y)$",
                                   "$\\sigma^2 \\propto E(y)[1-E(y)]$",
                                   "$\\sigma^2 \\propto [E(y)]^2$",
                                   "$\\sigma^2 \\propto [E(y)]^3$",
                                   "$\\sigma^2 \\propto [E(y)]^4$"
                                   ),
                "Transformation" = c("$y^\\prime = y$ (no transformation)",
                                     "$y^\\prime = \\sqrt{y}$ (Square root; Poisson)",
                                     "$y^\\prime = \\arcsin{(\\sqrt{y})}$ (arcsin; binomial proportions $0 \\leq y_i \\leq 1$)",
                                     "$y^\\prime = \\ln{(y)}$ (natural log)",
                                     "$y^\\prime = y^{-1/2}$ (reciprocal square root)",
                                     "$y^\\prime = y^{-1}$ (reciprocal)"
                                     )
                )
knitr::kable(x=x,
             caption = "Useful Variance-Stabilizing Transformations",
             format="markdown", escape=FALSE, 
             col.names=c("Relationship of $\\sigma^2$ to $E(y)$","Transformation")
             )

```



### Linearization

* Nonlinearity may be detected by **lack-of-fit** test
* **Intrinsically Linear** refers to a nonlinear function which can be transformed into a linear one
* One should check the model assumptions on the transformed residuals


```{r echo=FALSE, results='asis', escape=FALSE}
x <- data.frame(
  
  "Col1" = c(
    "$y=\\beta_0 x^{\\beta_1}$",
    "$y=\\beta_0 e^{\\beta_1 x}$",
    "$y=\\beta_0 + \\beta_1 \\log {x}$",
    "$y=\\frac{x}{\\beta_0x - \\beta_1}$"
    ),
  
  "Col2" = c(
    "$y^\\prime = \\log {y}, x^\\prime = \\log {x}$",
    "$y^\\prime = \\ln{y}$",
    "$x^\\prime = \\log{x}$",
    "$y^\\prime = 1/y, x^\\prime = 1/x$"
  ),
    
  "Col3" = c(
    "$y^\\prime = \\log {\\beta_0} + \\beta_1 x^\\prime$",
    "$y^\\prime = \\ln {\\beta_0} + \\beta_1 x$",
    "$y^\\prime = \\beta_0 + \\beta_1 x^\\prime$",
    "$y^\\prime = \\beta_0 - \\beta_1 x^\\prime$"
  )
)
knitr::kable(x=x,
             caption = "Linearizable Functions and Corresponding Linear Form",
             format="markdown", escape=FALSE, 
             col.names=c("Linearizable Function",
                         "Transformation",
                         "Linear Form")
             )

```

* When these transformations are applied, the least squares estimator has least squares properties with the transformed data, not the original

## Methods for Selecting a Transformation

While many transformations may be selected empirically, the following methods can be used to select the appropriate transformation more formally.

### Box-Cox Method

* Goal: Transform $y$ to correct non-normality or non-constant variance
* **Power Transformation**: $y^{\lambda}$, where 


### Box and Tidwell

Transformation on x