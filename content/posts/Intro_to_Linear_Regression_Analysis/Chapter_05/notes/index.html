---
title: Transformations and Weighting to Correct Model Inadequacies
author: Jeremy Buss
date: '2021-10-20'
slug: []
categories:
  - Introduction to Linear Regression Analysis - Montgomery/Peck/Vining
  - Applied Stats
  - Regression Analysis
tags:
  - R
  - linear regression
draft: false
katex: yes
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="model-assumptions" class="section level2">
<h2>Model Assumptions</h2>
<p>Regression model fitting has several implicit assumptions, including:</p>
<ul>
<li><span class="math inline">\(\epsilon \overset{iid}{\sim} NID(0,\sigma^2)\)</span>: <strong>mean 0</strong>, <strong>constant variance</strong>, <strong>normally distributed</strong>, and <strong>uncorrelated</strong></li>
<li>The form of the model (<strong>linearity</strong>) and the specification of the predictors are correct.</li>
<li>Check model adequacy by residual plots and lack-of-fit tests</li>
<li>Methods when some assumptions are violated:
<ul>
<li>Data Transformation</li>
<li>Generalized Least Squares (GLS)</li>
<li>Weighted Least Squares (WLS)</li>
</ul></li>
</ul>
</div>
<div id="data-transformation" class="section level2">
<h2>Data Transformation</h2>
<div id="variance-stabilization" class="section level3">
<h3>Variance Stabilization</h3>
<p>The constant variance assumption is often violated when the response <span class="math inline">\(y\)</span> follows a distribution which is related to the mean.<br />
* Problems can be identified by examining the residual plots
* Variance stabilizing transformations can be selected empirically
* If <span class="math inline">\(\sigma^2\)</span> is not constant, the coefficients will have larger standard errors (no longer BLUE)</p>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Useful Variance-Stabilizing Transformations</caption>
<colgroup>
<col width="30%" />
<col width="69%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Relationship of <span class="math inline">\(\sigma^2\)</span> to <span class="math inline">\(E(y)\)</span></th>
<th align="left">Transformation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\sigma^2 \propto \text{constant}\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = y\)</span> (no transformation)</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\sigma^2 \propto E(y)\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \sqrt{y}\)</span> (Square root; Poisson)</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\sigma^2 \propto E(y)[1-E(y)]\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \arcsin{(\sqrt{y})}\)</span> (arcsin; binomial proportions <span class="math inline">\(0 \leq y_i \leq 1\)</span>)</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\sigma^2 \propto [E(y)]^2\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \ln{(y)}\)</span> (natural log)</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\sigma^2 \propto [E(y)]^3\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = y^{-1/2}\)</span> (reciprocal square root)</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\sigma^2 \propto [E(y)]^4\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = y^{-1}\)</span> (reciprocal)</td>
</tr>
</tbody>
</table>
</div>
<div id="linearization" class="section level3">
<h3>Linearization</h3>
<ul>
<li>Nonlinearity may be detected by <strong>lack-of-fit</strong> test</li>
<li><strong>Intrinsically Linear</strong> refers to a nonlinear function which can be transformed into a linear one</li>
<li>One should check the model assumptions on the transformed residuals</li>
</ul>
<table>
<caption><span id="tab:unnamed-chunk-3">Table 2: </span>Linearizable Functions and Corresponding Linear Form</caption>
<colgroup>
<col width="26%" />
<col width="34%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Linearizable Function</th>
<th align="left">Transformation</th>
<th align="left">Linear Form</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(y=\beta_0 x^{\beta_1}\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \log {y}, x^\prime = \log {x}\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \log {\beta_0} + \beta_1 x^\prime\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(y=\beta_0 e^{\beta_1 x}\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \ln{y}\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \ln {\beta_0} + \beta_1 x\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(y=\beta_0 + \beta_1 \log {x}\)</span></td>
<td align="left"><span class="math inline">\(x^\prime = \log{x}\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \beta_0 + \beta_1 x^\prime\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(y=\frac{x}{\beta_0x - \beta_1}\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = 1/y, x^\prime = 1/x\)</span></td>
<td align="left"><span class="math inline">\(y^\prime = \beta_0 - \beta_1 x^\prime\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li>When these transformations are applied, the least squares estimator has least squares properties with the transformed data, not the original</li>
</ul>
</div>
</div>
<div id="methods-for-selecting-a-transformation" class="section level2">
<h2>Methods for Selecting a Transformation</h2>
<p>While many transformations may be selected empirically, the following methods can be used to select the appropriate transformation more formally.</p>
<div id="box-cox-method" class="section level3">
<h3>Box-Cox Method</h3>
<ul>
<li>Goal: Transform <span class="math inline">\(y\)</span> to correct non-normality or non-constant variance</li>
<li><strong>Power Transformation</strong>: <span class="math inline">\(y^{\lambda}\)</span>, where <span class="math inline">\(\lambda\)</span> is a parameter to be determined</li>
</ul>
<p><a href="https://www.nuffield.ox.ac.uk/users/cox/cox72.pdf">Box and Cox (1964) - Method</a>:
<span class="math display">\[
y_i^{(\lambda)}=
\begin{cases}
   \frac{y_i^{\lambda}-1}{\lambda \dot{y}^{\lambda - 1}}, &amp; \lambda \ne 0\\
   \dot{y} \ln{y_i}, &amp; \lambda = 0
\end{cases}
\]</span></p>
<ul>
<li>Where <span class="math inline">\(\dot{y} = \left ( \prod_{i=1}^n y_i \right )^{1/n}\)</span> is the geometric mean of the observations</li>
<li>The units of measurement do not change as <span class="math inline">\(\lambda\)</span> changes</li>
<li>Models with different <span class="math inline">\(\lambda\)</span> are comparable</li>
</ul>
<p>The model to be fit is:</p>
<p><span class="math display">\[
\mathbf{y}^{(\lambda)}=\mathbf{X\beta}+\mathbf{\epsilon}
\]</span></p>
<div id="computation-procedure" class="section level4">
<h4>Computation Procedure</h4>
<ol style="list-style-type: decimal">
<li>Create a grid of <span class="math inline">\(\lambda\)</span> values</li>
<li>For each value of <span class="math inline">\(\lambda\)</span> in the grid, regress <span class="math inline">\(y^{(\lambda)}\)</span> on the predictors, and obtain <span class="math inline">\(SS_{Res}(\lambda)\)</span></li>
<li>Take the <span class="math inline">\(\lambda\)</span> that leads to the smallest <span class="math inline">\(SS_{Res}(\lambda)\)</span></li>
</ol>
<p>Once <span class="math inline">\(\lambda\)</span> is selected, we are free to fit the model using <span class="math inline">\(y^{\lambda}\)</span> as the response if <span class="math inline">\(\lambda \ne 0\)</span>, and <span class="math inline">\(\ln{y}\)</span> if <span class="math inline">\(\lambda = 0\)</span></p>
</div>
</div>
<div id="box-and-tidwell" class="section level3">
<h3>Box and Tidwell</h3>
<ul>
<li>Goal: the relationship between <span class="math inline">\(y\)</span> and the transformed regressors is approximately linear.</li>
<li><span class="math inline">\(\epsilon \overset{iid}{\sim} NID(0,\sigma^2)\)</span> is at least approximately satisfied</li>
<li>Box and Tidwell (1962) proposed a procedure for estimating <span class="math inline">\(\alpha_1, \alpha_2, \dots , \alpha_k\)</span> in a model of the type</li>
</ul>
<p><span class="math display">\[
y=\beta_0+\beta_1 z_1+\dots+\beta_k z_k + \epsilon
\]</span></p>
<p>where</p>
<p><span class="math display">\[
z_j=
\begin{cases}
   x_j^{\alpha_j}, &amp; \alpha_j \ne 0\\
   \ln{(x_j)}, &amp; \alpha_j = 0
\end{cases}
\]</span></p>
</div>
</div>
